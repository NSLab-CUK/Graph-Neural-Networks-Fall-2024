{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca3dcbfb-8bae-48de-94b2-288f1c0b132d",
   "metadata": {},
   "source": [
    "### Assignment 1. Let's program the GT (Graph Transformer) model on Graph-level classification on ogbg-molhiv dataset (https://ogb.stanford.edu/docs/graphprop/#ogbg-mol) with the Readout function: Max pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69ac513b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.4.1\n",
      "  Downloading torch-2.4.1-cp39-cp39-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting torchvision==0.19.1\n",
      "  Downloading torchvision-0.19.1-cp39-cp39-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
      "Collecting torchaudio==2.4.1\n",
      "  Downloading torchaudio-2.4.1-cp39-cp39-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: filelock in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch==2.4.1) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch==2.4.1) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch==2.4.1) (1.13.2)\n",
      "Requirement already satisfied: networkx in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch==2.4.1) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch==2.4.1) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch==2.4.1) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch==2.4.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch==2.4.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch==2.4.1) (12.1.105)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.1)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch==2.4.1) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch==2.4.1) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch==2.4.1) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch==2.4.1) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch==2.4.1) (12.1.0.106)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.1)\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch==2.4.1) (12.1.105)\n",
      "Collecting triton==3.0.0 (from torch==2.4.1)\n",
      "  Downloading triton-3.0.0-1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: numpy in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torchvision==0.19.1) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torchvision==0.19.1) (10.4.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1) (12.6.77)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from jinja2->torch==2.4.1) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from sympy->torch==2.4.1) (1.3.0)\n",
      "Downloading torch-2.4.1-cp39-cp39-manylinux1_x86_64.whl (797.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.19.1-cp39-cp39-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.4.1-cp39-cp39-manylinux1_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.0.0-1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, nvidia-nccl-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.1.0\n",
      "    Uninstalling triton-2.1.0:\n",
      "      Successfully uninstalled triton-2.1.0\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.18.1\n",
      "    Uninstalling nvidia-nccl-cu12-2.18.1:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.18.1\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 8.9.2.26\n",
      "    Uninstalling nvidia-cudnn-cu12-8.9.2.26:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-8.9.2.26\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.0+cu118\n",
      "    Uninstalling torch-2.1.0+cu118:\n",
      "      Successfully uninstalled torch-2.1.0+cu118\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.16.0+cu118\n",
      "    Uninstalling torchvision-0.16.0+cu118:\n",
      "      Successfully uninstalled torchvision-0.16.0+cu118\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.1.0+cu118\n",
      "    Uninstalling torchaudio-2.1.0+cu118:\n",
      "      Successfully uninstalled torchaudio-2.1.0+cu118\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "dgl 2.4.0+cu118 requires torch<=2.4.0, but you have torch 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cudnn-cu12-9.1.0.70 nvidia-nccl-cu12-2.20.5 torch-2.4.1 torchaudio-2.4.1 torchvision-0.19.1 triton-3.0.0\n",
      "Looking in links: https://data.dgl.ai/wheels/torch-2.4/cu124/repo.html\n",
      "Requirement already satisfied: dgl in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (2.4.0+cu118)\n",
      "Requirement already satisfied: networkx>=2.1 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from dgl) (3.2.1)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from dgl) (1.26.4)\n",
      "Requirement already satisfied: packaging in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from dgl) (24.1)\n",
      "Requirement already satisfied: pandas in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from dgl) (2.2.3)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from dgl) (5.9.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from dgl) (2.9.2)\n",
      "Requirement already satisfied: pyyaml in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from dgl) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from dgl) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from dgl) (1.13.1)\n",
      "Requirement already satisfied: tqdm in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from dgl) (4.66.5)\n",
      "Collecting torch<=2.4.0 (from dgl)\n",
      "  Downloading torch-2.4.0-cp39-cp39-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from pydantic>=2.0->dgl) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from pydantic>=2.0->dgl) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from pydantic>=2.0->dgl) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from requests>=2.19.0->dgl) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from requests>=2.19.0->dgl) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from requests>=2.19.0->dgl) (2024.8.30)\n",
      "Requirement already satisfied: filelock in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch<=2.4.0->dgl) (3.13.1)\n",
      "Requirement already satisfied: sympy in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch<=2.4.0->dgl) (1.13.2)\n",
      "Requirement already satisfied: jinja2 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch<=2.4.0->dgl) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch<=2.4.0->dgl) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch<=2.4.0->dgl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch<=2.4.0->dgl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch<=2.4.0->dgl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch<=2.4.0->dgl) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch<=2.4.0->dgl) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch<=2.4.0->dgl) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch<=2.4.0->dgl) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch<=2.4.0->dgl) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch<=2.4.0->dgl) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch<=2.4.0->dgl) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch<=2.4.0->dgl) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch<=2.4.0->dgl) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<=2.4.0->dgl) (12.6.77)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from pandas->dgl) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from pandas->dgl) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from pandas->dgl) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->dgl) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from jinja2->torch<=2.4.0->dgl) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from sympy->torch<=2.4.0->dgl) (1.3.0)\n",
      "Downloading torch-2.4.0-cp39-cp39-manylinux1_x86_64.whl (797.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.4.1\n",
      "    Uninstalling torch-2.4.1:\n",
      "      Successfully uninstalled torch-2.4.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.4.1 requires torch==2.4.1, but you have torch 2.4.0 which is incompatible.\n",
      "torchvision 0.19.1 requires torch==2.4.1, but you have torch 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-2.4.0\n",
      "Requirement already satisfied: chardet in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (5.2.0)\n",
      "Requirement already satisfied: ogb in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (1.3.6)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from ogb) (2.4.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from ogb) (1.26.4)\n",
      "Requirement already satisfied: tqdm>=4.29.0 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from ogb) (4.66.5)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from ogb) (1.5.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from ogb) (2.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from ogb) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.24.0 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from ogb) (2.2.2)\n",
      "Requirement already satisfied: outdated>=0.2.0 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from ogb) (0.2.2)\n",
      "Requirement already satisfied: setuptools>=44 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from outdated>=0.2.0->ogb) (72.1.0)\n",
      "Requirement already satisfied: littleutils in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from outdated>=0.2.0->ogb) (0.2.4)\n",
      "Requirement already satisfied: requests in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from outdated>=0.2.0->ogb) (2.32.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from pandas>=0.24.0->ogb) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from pandas>=0.24.0->ogb) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from pandas>=0.24.0->ogb) (2024.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from scikit-learn>=0.20.0->ogb) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from scikit-learn>=0.20.0->ogb) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from scikit-learn>=0.20.0->ogb) (3.5.0)\n",
      "Requirement already satisfied: filelock in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (1.13.2)\n",
      "Requirement already satisfied: networkx in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from torch>=1.6.0->ogb) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->ogb) (12.6.77)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from jinja2->torch>=1.6.0->ogb) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from requests->outdated>=0.2.0->ogb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from requests->outdated>=0.2.0->ogb) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from requests->outdated>=0.2.0->ogb) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from sympy->torch>=1.6.0->ogb) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1\n",
    "!pip install dgl -f https://data.dgl.ai/wheels/torch-2.4/cu124/repo.html\n",
    "!pip install chardet\n",
    "!pip install ogb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afd42754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (6.0.1)\n",
      "Requirement already satisfied: pydantic in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (2.9.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from pydantic) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from pydantic) (4.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyyaml\n",
    "!pip install pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f9ca93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DGL installed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "os.environ['DGLBACKEND'] = \"pytorch\"\n",
    "\n",
    "try:\n",
    "    import dgl\n",
    "    installed = True\n",
    "except ImportError:\n",
    "    installed = False\n",
    "print(\"DGL installed!\" if installed else \"Failed to install DGL!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f2c96ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class SparseMHA(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size=80, num_heads=8):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = hidden_size // num_heads\n",
    "        self.scaling = self.head_dim**-0.5\n",
    "\n",
    "        self.q_proj = nn.Linear(hidden_size, hidden_size)\n",
    "        self.k_proj = nn.Linear(hidden_size, hidden_size)\n",
    "        self.v_proj = nn.Linear(hidden_size, hidden_size)\n",
    "        self.out_proj = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, A, h):\n",
    "        N = len(h)\n",
    "\n",
    "        q = self.q_proj(h).reshape(N, self.head_dim, self.num_heads)\n",
    "        q *= self.scaling\n",
    "\n",
    "        k = self.k_proj(h).reshape(N, self.head_dim, self.num_heads)\n",
    "\n",
    "        v = self.v_proj(h).reshape(N, self.head_dim, self.num_heads)\n",
    "\n",
    "        attn = torch.bmm(q.transpose(1, 2), k)\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "\n",
    "        out = torch.bmm(attn, v.transpose(1, 2))\n",
    "\n",
    "        out = out.transpose(1, 2).reshape(N, -1)\n",
    "        return self.out_proj(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6318a2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GTLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size=80, num_heads=8):\n",
    "        super().__init__()\n",
    "        self.MHA = SparseMHA(hidden_size=hidden_size, num_heads=num_heads)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.FFN1 = nn.Linear(hidden_size, hidden_size * 2)\n",
    "        self.FFN2 = nn.Linear(hidden_size * 2, hidden_size)\n",
    "\n",
    "    def forward(self, A, h):\n",
    "        h1 = h\n",
    "        h = self.MHA(A, h)\n",
    "        h = self.batchnorm1(h + h1)\n",
    "\n",
    "        h2 = h\n",
    "        h = self.FFN2(F.relu(self.FFN1(h)))\n",
    "        h = h2 + h\n",
    "\n",
    "        return self.batchnorm2(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87e29ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from dgl.nn import MaxPooling\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "class GTModel(nn.Module):\n",
    "    def __init__(self, out_size, hidden_size=80, pos_enc_size=2, num_layers=8, num_heads=8):\n",
    "        super().__init__()\n",
    "        self.atom_encoder = AtomEncoder(hidden_size)\n",
    "        self.pos_linear = nn.Linear(pos_enc_size, hidden_size)\n",
    "        self.layers = nn.ModuleList(\n",
    "            [GTLayer(hidden_size, num_heads) for _ in range(num_layers)]\n",
    "        )\n",
    "        self.pooler = MaxPooling()\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size // 2, hidden_size // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size // 4, out_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, g, X, pos_enc):\n",
    "        indices = torch.stack(g.edges())\n",
    "        N = g.num_nodes()\n",
    "        A = torch.zeros((N, N), device=X.device)\n",
    "        A[indices[0], indices[1]] = 1\n",
    "\n",
    "        h = self.atom_encoder(X) + self.pos_linear(pos_enc)\n",
    "        for layer in self.layers:\n",
    "            h = layer(A, h)\n",
    "        h = self.pooler(g, h)\n",
    "\n",
    "        return self.predictor(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "783db823",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader, evaluator, device):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for batched_g, labels in dataloader:\n",
    "        batched_g, labels = batched_g.to(device), labels.to(device)\n",
    "        y_hat = model(batched_g, batched_g.ndata[\"feat\"], batched_g.ndata[\"PE\"])\n",
    "        y_true.append(labels.view(y_hat.shape).detach().cpu())\n",
    "        y_pred.append(y_hat.detach().cpu())\n",
    "    y_true = torch.cat(y_true, dim=0).numpy()\n",
    "    y_pred = torch.cat(y_pred, dim=0).numpy()\n",
    "    input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
    "    return evaluator.eval(input_dict)[\"rocauc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01d580e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages/torch_cluster/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n"
     ]
    }
   ],
   "source": [
    "from dgl.dataloading import GraphDataLoader\n",
    "from ogb.graphproppred import collate_dgl\n",
    "\n",
    "def train(model, dataset, evaluator, device):\n",
    "    train_dataloader = GraphDataLoader(\n",
    "        dataset[dataset.train_idx],\n",
    "        batch_size=256,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_dgl,\n",
    "    )\n",
    "    valid_dataloader = GraphDataLoader(\n",
    "        dataset[dataset.val_idx], batch_size=256, collate_fn=collate_dgl\n",
    "    )\n",
    "    test_dataloader = GraphDataLoader(\n",
    "        dataset[dataset.test_idx], batch_size=256, collate_fn=collate_dgl\n",
    "    )\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    num_epochs = 5\n",
    "    scheduler = optim.lr_scheduler.StepLR(\n",
    "        optimizer, step_size=num_epochs, gamma=0.5\n",
    "    )\n",
    "    loss_fcn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for batched_g, labels in train_dataloader:\n",
    "            batched_g, labels = batched_g.to(device), labels.to(device)\n",
    "            logits = model(\n",
    "                batched_g, batched_g.ndata[\"feat\"], batched_g.ndata[\"PE\"]\n",
    "            )\n",
    "            loss = loss_fcn(logits, labels.float())\n",
    "            total_loss += loss.item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "        avg_loss = total_loss / len(train_dataloader)\n",
    "        val_metric = evaluate(model, valid_dataloader, evaluator, device)\n",
    "        test_metric = evaluate(model, test_dataloader, evaluator, device)\n",
    "        print(\n",
    "            f\"Epoch: {epoch:03d}, Loss: {avg_loss:.4f}, \"\n",
    "            f\"Val: {val_metric:.4f}, Test: {test_metric:.4f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8984282a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://snap.stanford.edu/ogb/data/graphproppred/csv_mol_download/hiv.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded 0.00 GB: 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/OGB/hiv.zip\n",
      "Loading necessary files...\n",
      "This might take a while.\n",
      "Processing graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41127/41127 [00:00<00:00, 183243.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting graphs into DGL objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41127/41127 [00:04<00:00, 8585.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Laplacian PE:   0%|          | 0/4000 [00:00<?, ?it/s]/home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages/dgl/transforms/functional.py:3725: DGLWarning: dgl.laplacian_pe will be deprecated. Use dgl.lap_pe please.\n",
      "  dgl_warning(\"dgl.laplacian_pe will be deprecated. Use dgl.lap_pe please.\")\n",
      "Computing Laplacian PE: 100%|██████████| 4000/4000 [00:06<00:00, 604.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.5285, Val: 0.5115, Test: 0.3787\n",
      "Epoch: 001, Loss: 0.2620, Val: 0.4814, Test: 0.3806\n",
      "Epoch: 002, Loss: 0.1704, Val: 0.4946, Test: 0.4143\n",
      "Epoch: 003, Loss: 0.1602, Val: 0.5638, Test: 0.5340\n",
      "Epoch: 004, Loss: 0.1583, Val: 0.6403, Test: 0.5358\n"
     ]
    }
   ],
   "source": [
    "from dgl.data import AsGraphPredDataset\n",
    "from ogb.graphproppred import DglGraphPropPredDataset, Evaluator\n",
    "from tqdm import tqdm\n",
    "from ogb.graphproppred.mol_encoder import AtomEncoder\n",
    "\n",
    "dev = torch.device(\"cuda:0\")\n",
    "\n",
    "pos_enc_size = 8\n",
    "dataset = AsGraphPredDataset(\n",
    "    DglGraphPropPredDataset(\"ogbg-molhiv\", \"./data/OGB\")\n",
    ")\n",
    "evaluator = Evaluator(\"ogbg-molhiv\")\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "train_size = len(dataset.train_idx)\n",
    "val_size = len(dataset.val_idx)\n",
    "test_size = len(dataset.test_idx)\n",
    "dataset.train_idx = dataset.train_idx[\n",
    "    torch.LongTensor(random.sample(range(train_size), 2000))\n",
    "]\n",
    "dataset.val_idx = dataset.val_idx[\n",
    "    torch.LongTensor(random.sample(range(val_size), 1000))\n",
    "]\n",
    "dataset.test_idx = dataset.test_idx[\n",
    "    torch.LongTensor(random.sample(range(test_size), 1000))\n",
    "]\n",
    "\n",
    "indices = torch.cat([dataset.train_idx, dataset.val_idx, dataset.test_idx])\n",
    "for idx in tqdm(indices, desc=\"Computing Laplacian PE\"):\n",
    "    g, _ = dataset[idx]\n",
    "    g.ndata[\"PE\"] = dgl.laplacian_pe(g, k=pos_enc_size, padding=True)\n",
    "\n",
    "out_size = dataset.num_tasks\n",
    "model = GTModel(out_size=out_size, pos_enc_size=pos_enc_size).to(dev)\n",
    "\n",
    "train(model, dataset, evaluator, dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd65cba6-fcad-41a1-a6ef-cc209e6f77c9",
   "metadata": {},
   "source": [
    "### Assignment 2. Let's program the GT (Graph Transformer) model on Graph-level classification on ogbg-molhiv dataset (https://ogb.stanford.edu/docs/graphprop/#ogbg-mol) with the Readout function: average pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ccfab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from dgl.nn import AvgPooling\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "class GTModel(nn.Module):\n",
    "    def __init__(self, out_size, hidden_size=80, pos_enc_size=2, num_layers=8, num_heads=8):\n",
    "        super().__init__()\n",
    "        self.atom_encoder = AtomEncoder(hidden_size)\n",
    "        self.pos_linear = nn.Linear(pos_enc_size, hidden_size)\n",
    "        self.layers = nn.ModuleList(\n",
    "            [GTLayer(hidden_size, num_heads) for _ in range(num_layers)]\n",
    "        )\n",
    "        self.pooler = AvgPooling()\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size // 2, hidden_size // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size // 4, out_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, g, X, pos_enc):\n",
    "        indices = torch.stack(g.edges())\n",
    "        N = g.num_nodes()\n",
    "        A = torch.zeros((N, N), device=X.device)\n",
    "        A[indices[0], indices[1]] = 1\n",
    "\n",
    "        h = self.atom_encoder(X) + self.pos_linear(pos_enc)\n",
    "        for layer in self.layers:\n",
    "            h = layer(A, h)\n",
    "        h = self.pooler(g, h)\n",
    "\n",
    "        return self.predictor(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c67c81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader, evaluator, device):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for batched_g, labels in dataloader:\n",
    "        batched_g, labels = batched_g.to(device), labels.to(device)\n",
    "        y_hat = model(batched_g, batched_g.ndata[\"feat\"], batched_g.ndata[\"PE\"])\n",
    "        y_true.append(labels.view(y_hat.shape).detach().cpu())\n",
    "        y_pred.append(y_hat.detach().cpu())\n",
    "    y_true = torch.cat(y_true, dim=0).numpy()\n",
    "    y_pred = torch.cat(y_pred, dim=0).numpy()\n",
    "    input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
    "    return evaluator.eval(input_dict)[\"rocauc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "022b0923",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.dataloading import GraphDataLoader\n",
    "from ogb.graphproppred import collate_dgl\n",
    "\n",
    "def train(model, dataset, evaluator, device):\n",
    "    train_dataloader = GraphDataLoader(\n",
    "        dataset[dataset.train_idx],\n",
    "        batch_size=256,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_dgl,\n",
    "    )\n",
    "    valid_dataloader = GraphDataLoader(\n",
    "        dataset[dataset.val_idx], batch_size=256, collate_fn=collate_dgl\n",
    "    )\n",
    "    test_dataloader = GraphDataLoader(\n",
    "        dataset[dataset.test_idx], batch_size=256, collate_fn=collate_dgl\n",
    "    )\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    num_epochs = 5\n",
    "    scheduler = optim.lr_scheduler.StepLR(\n",
    "        optimizer, step_size=num_epochs, gamma=0.5\n",
    "    )\n",
    "    loss_fcn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for batched_g, labels in train_dataloader:\n",
    "            batched_g, labels = batched_g.to(device), labels.to(device)\n",
    "            logits = model(\n",
    "                batched_g, batched_g.ndata[\"feat\"], batched_g.ndata[\"PE\"]\n",
    "            )\n",
    "            loss = loss_fcn(logits, labels.float())\n",
    "            total_loss += loss.item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "        avg_loss = total_loss / len(train_dataloader)\n",
    "        val_metric = evaluate(model, valid_dataloader, evaluator, device)\n",
    "        test_metric = evaluate(model, test_dataloader, evaluator, device)\n",
    "        print(\n",
    "            f\"Epoch: {epoch:03d}, Loss: {avg_loss:.4f}, \"\n",
    "            f\"Val: {val_metric:.4f}, Test: {test_metric:.4f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc7f0a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Laplacian PE:   0%|          | 0/4000 [00:00<?, ?it/s]/home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages/dgl/transforms/functional.py:3725: DGLWarning: dgl.laplacian_pe will be deprecated. Use dgl.lap_pe please.\n",
      "  dgl_warning(\"dgl.laplacian_pe will be deprecated. Use dgl.lap_pe please.\")\n",
      "Computing Laplacian PE: 100%|██████████| 4000/4000 [00:06<00:00, 606.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.6017, Val: 0.4258, Test: 0.4385\n",
      "Epoch: 001, Loss: 0.4915, Val: 0.5116, Test: 0.4836\n",
      "Epoch: 002, Loss: 0.3812, Val: 0.5715, Test: 0.5165\n",
      "Epoch: 003, Loss: 0.2832, Val: 0.6053, Test: 0.5512\n",
      "Epoch: 004, Loss: 0.2185, Val: 0.6643, Test: 0.6440\n"
     ]
    }
   ],
   "source": [
    "from dgl.data import AsGraphPredDataset\n",
    "from ogb.graphproppred import DglGraphPropPredDataset, Evaluator\n",
    "from tqdm import tqdm\n",
    "from ogb.graphproppred.mol_encoder import AtomEncoder\n",
    "\n",
    "dev = torch.device(\"cuda:0\")\n",
    "\n",
    "pos_enc_size = 8\n",
    "dataset = AsGraphPredDataset(\n",
    "    DglGraphPropPredDataset(\"ogbg-molhiv\", \"./data/OGB\")\n",
    ")\n",
    "evaluator = Evaluator(\"ogbg-molhiv\")\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "train_size = len(dataset.train_idx)\n",
    "val_size = len(dataset.val_idx)\n",
    "test_size = len(dataset.test_idx)\n",
    "dataset.train_idx = dataset.train_idx[\n",
    "    torch.LongTensor(random.sample(range(train_size), 2000))\n",
    "]\n",
    "dataset.val_idx = dataset.val_idx[\n",
    "    torch.LongTensor(random.sample(range(val_size), 1000))\n",
    "]\n",
    "dataset.test_idx = dataset.test_idx[\n",
    "    torch.LongTensor(random.sample(range(test_size), 1000))\n",
    "]\n",
    "\n",
    "indices = torch.cat([dataset.train_idx, dataset.val_idx, dataset.test_idx])\n",
    "for idx in tqdm(indices, desc=\"Computing Laplacian PE\"):\n",
    "    g, _ = dataset[idx]\n",
    "    g.ndata[\"PE\"] = dgl.laplacian_pe(g, k=pos_enc_size, padding=True)\n",
    "\n",
    "out_size = dataset.num_tasks\n",
    "model = GTModel(out_size=out_size, pos_enc_size=pos_enc_size).to(dev)\n",
    "\n",
    "train(model, dataset, evaluator, dev)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
