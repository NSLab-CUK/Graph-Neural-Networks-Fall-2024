{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca3dcbfb-8bae-48de-94b2-288f1c0b132d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Assignment 1. Given the MUTAG dataset from Torch Geometric: \n",
    "\n",
    "Questions: Build a Relational GCN model to learn the MUTAG dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f8821cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages/torch_cluster/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdflib in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (7.1.1)\n",
      "Requirement already satisfied: isodate<1.0.0,>=0.7.2 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from rdflib) (0.7.2)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in /home/user/anaconda3/envs/GNN2/lib/python3.9/site-packages (from rdflib) (3.1.2)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os.path as osp\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.datasets import Entities\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "!pip install rdflib\n",
    "\n",
    "dataset = 'MUTAG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fae7a63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple, Union\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import Parameter\n",
    "\n",
    "import torch_geometric.backend\n",
    "import torch_geometric.typing\n",
    "from torch_geometric import is_compiling\n",
    "from torch_geometric.index import index2ptr\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.inits import glorot, zeros\n",
    "from torch_geometric.typing import (\n",
    "    Adj,\n",
    "    OptTensor,\n",
    "    SparseTensor,\n",
    "    pyg_lib,\n",
    "    torch_sparse,\n",
    ")\n",
    "from torch_geometric.utils import index_sort, one_hot, scatter, spmm\n",
    "\n",
    "def masked_edge_index(edge_index: Adj, edge_mask: Tensor) -> Adj:\n",
    "     if isinstance(edge_index, Tensor):\n",
    "        return edge_index[:, edge_mask]\n",
    "     return torch_sparse.masked_select_nnz(edge_index, edge_mask, layout='coo')\n",
    "\n",
    "class RGCNConv(MessagePassing):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: Union[int, Tuple[int, int]],\n",
    "        out_channels: int,\n",
    "        num_relations: int,\n",
    "        num_bases: Optional[int] = None,\n",
    "        num_blocks: Optional[int] = None,\n",
    "        aggr: str = 'mean',\n",
    "        root_weight: bool = True,\n",
    "        is_sorted: bool = False,\n",
    "        bias: bool = True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        kwargs.setdefault('aggr', aggr)\n",
    "        super().__init__(node_dim=0, **kwargs)\n",
    "\n",
    "        if num_bases is not None and num_blocks is not None:\n",
    "            raise ValueError('Can not apply both basis-decomposition and '\n",
    "                             'block-diagonal-decomposition at the same time.')\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_relations = num_relations\n",
    "        self.num_bases = num_bases\n",
    "        self.num_blocks = num_blocks\n",
    "        self.is_sorted = is_sorted\n",
    "\n",
    "        if isinstance(in_channels, int):\n",
    "            in_channels = (in_channels, in_channels)\n",
    "        self.in_channels_l = in_channels[0]\n",
    "\n",
    "        self._use_segment_matmul_heuristic_output: torch.jit.Attribute(\n",
    "            None, Optional[float])\n",
    "\n",
    "        if num_bases is not None:\n",
    "            self.weight = Parameter(\n",
    "                torch.empty(num_bases, in_channels[0], out_channels))\n",
    "            self.comp = Parameter(torch.empty(num_relations, num_bases))\n",
    "\n",
    "        elif num_blocks is not None:\n",
    "            assert (in_channels[0] % num_blocks == 0\n",
    "                    and out_channels % num_blocks == 0)\n",
    "            self.weight = Parameter(\n",
    "                torch.empty(num_relations, num_blocks,\n",
    "                            in_channels[0] // num_blocks,\n",
    "                            out_channels // num_blocks))\n",
    "            self.register_parameter('comp', None)\n",
    "\n",
    "        else:\n",
    "            self.weight = Parameter(\n",
    "                torch.empty(num_relations, in_channels[0], out_channels))\n",
    "            self.register_parameter('comp', None)\n",
    "\n",
    "        if root_weight:\n",
    "            self.root = Parameter(torch.empty(in_channels[1], out_channels))\n",
    "        else:\n",
    "            self.register_parameter('root', None)\n",
    "\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.empty(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "\n",
    "        super().reset_parameters()\n",
    "        glorot(self.weight)\n",
    "        glorot(self.comp)\n",
    "        glorot(self.root)\n",
    "        zeros(self.bias)\n",
    "\n",
    "    def forward(self, x: Union[OptTensor, Tuple[OptTensor, Tensor]],\n",
    "                edge_index: Adj, edge_type: OptTensor = None):\n",
    "        x_l: OptTensor = None\n",
    "        if isinstance(x, tuple):\n",
    "            x_l = x[0]\n",
    "        else:\n",
    "            x_l = x\n",
    "        if x_l is None:\n",
    "            x_l = torch.arange(self.in_channels_l, device=self.weight.device)\n",
    "\n",
    "        x_r: Tensor = x_l\n",
    "        if isinstance(x, tuple):\n",
    "            x_r = x[1]\n",
    "\n",
    "        size = (x_l.size(0), x_r.size(0))\n",
    "\n",
    "        if isinstance(edge_index, SparseTensor):\n",
    "            edge_type = edge_index.storage.value()\n",
    "        assert edge_type is not None\n",
    "\n",
    "        out = torch.zeros(x_r.size(0), self.out_channels, device=x_r.device)\n",
    "\n",
    "        weight = self.weight\n",
    "        if self.num_bases is not None:\n",
    "            weight = (self.comp @ weight.view(self.num_bases, -1)).view(\n",
    "                self.num_relations, self.in_channels_l, self.out_channels)\n",
    "\n",
    "        if self.num_blocks is not None:\n",
    "            if not torch.is_floating_point(x_r):\n",
    "                raise ValueError('Block-diagonal decomposition not supported '\n",
    "                                 'for non-continuous input features.')\n",
    "\n",
    "            for i in range(self.num_relations):\n",
    "                tmp = masked_edge_index(edge_index, edge_type == i)\n",
    "                h = self.propagate(tmp, x=x_l, edge_type_ptr=None, size=size)\n",
    "                h = h.view(-1, weight.size(1), weight.size(2))\n",
    "                h = torch.einsum('abc,bcd->abd', h, weight[i])\n",
    "                out = out + h.contiguous().view(-1, self.out_channels)\n",
    "\n",
    "        else:\n",
    "            ...\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2333ad5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastRGCNConv(RGCNConv):\n",
    "    def forward(self, x: Union[OptTensor, Tuple[OptTensor, Tensor]],\n",
    "                edge_index: Adj, edge_type: OptTensor = None):\n",
    "\n",
    "        self.fuse = False\n",
    "        assert self.aggr in ['add', 'sum', 'mean']\n",
    "\n",
    "        x_l: OptTensor = None\n",
    "        if isinstance(x, tuple):\n",
    "            x_l = x[0]\n",
    "        else:\n",
    "            x_l = x\n",
    "        if x_l is None:\n",
    "            x_l = torch.arange(self.in_channels_l, device=self.weight.device)\n",
    "\n",
    "        x_r: Tensor = x_l\n",
    "        if isinstance(x, tuple):\n",
    "            x_r = x[1]\n",
    "\n",
    "        size = (x_l.size(0), x_r.size(0))\n",
    "\n",
    "        out = self.propagate(edge_index, x=x_l, edge_type=edge_type, size=size)\n",
    "\n",
    "        root = self.root\n",
    "        if root is not None:\n",
    "            if not torch.is_floating_point(x_r):\n",
    "                out = out + root[x_r]\n",
    "            else:\n",
    "                out = out + x_r @ root\n",
    "\n",
    "        if self.bias is not None:\n",
    "            out = out + self.bias\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def message(self, x_j: Tensor, edge_type: Tensor,\n",
    "                edge_index_j: Tensor) -> Tensor:\n",
    "        weight = self.weight\n",
    "        if self.num_bases is not None:\n",
    "            weight = (self.comp @ weight.view(self.num_bases, -1)).view(\n",
    "                self.num_relations, self.in_channels_l, self.out_channels)\n",
    "\n",
    "        if self.num_blocks is not None:\n",
    "            if not torch.is_floating_point(x_j):\n",
    "                raise ValueError('Block-diagonal decomposition not supported '\n",
    "                                 'for non-continuous input features.')\n",
    "\n",
    "            weight = weight[edge_type].view(-1, weight.size(2), weight.size(3))\n",
    "            x_j = x_j.view(-1, 1, weight.size(1))\n",
    "            return torch.bmm(x_j, weight).view(-1, self.out_channels)\n",
    "\n",
    "        else:\n",
    "            if not torch.is_floating_point(x_j):\n",
    "                weight_index = edge_type * weight.size(1) + edge_index_j\n",
    "                return weight.view(-1, self.out_channels)[weight_index]\n",
    "\n",
    "            return torch.bmm(x_j.unsqueeze(-2), weight[edge_type]).squeeze(-2)\n",
    "\n",
    "    def aggregate(self, inputs: Tensor, edge_type: Tensor, index: Tensor,\n",
    "                  dim_size: Optional[int] = None) -> Tensor:\n",
    "\n",
    "        if self.aggr == 'mean':\n",
    "            norm = one_hot(edge_type, self.num_relations, dtype=inputs.dtype)\n",
    "            norm = scatter(norm, index, dim=0, dim_size=dim_size)[index]\n",
    "            norm = torch.gather(norm, 1, edge_type.view(-1, 1))\n",
    "            norm = 1. / norm.clamp_(1.)\n",
    "            inputs = norm * inputs\n",
    "\n",
    "        return scatter(inputs, index, dim=self.node_dim, dim_size=dim_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cac0ee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset in ['AIFB', 'MUTAG']:\n",
    "    Conv = FastRGCNConv\n",
    "else:\n",
    "    Conv = RGCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fead3bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://data.dgl.ai/dataset/mutag.tgz\n",
      "Extracting data/Entities/mutag.tgz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "path = osp.join('data', 'Entities')\n",
    "dataset = Entities(path, dataset)\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2cb1916",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_idx = torch.cat([data.train_idx, data.test_idx], dim=0)\n",
    "node_idx, edge_index, mapping, edge_mask = k_hop_subgraph(\n",
    "    node_idx, 2, data.edge_index, relabel_nodes=True)\n",
    "\n",
    "data.num_nodes = node_idx.size(0)\n",
    "data.edge_index = edge_index\n",
    "data.edge_type = data.edge_type[edge_mask]\n",
    "data.train_idx = mapping[:data.train_idx.size(0)]\n",
    "data.test_idx = mapping[data.train_idx.size(0):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d045d5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv(data.num_nodes, 16, dataset.num_relations,\n",
    "                          num_bases=30)\n",
    "        self.conv2 = Conv(16, dataset.num_classes, dataset.num_relations,\n",
    "                          num_bases=30)\n",
    "\n",
    "    def forward(self, edge_index, edge_type):\n",
    "        x = F.relu(self.conv1(None, edge_index, edge_type))\n",
    "        x = self.conv2(x, edge_index, edge_type)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8b1ad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0860cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu') if dataset == 'AM' else device\n",
    "model, data = Net().to(device), data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57f01d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.edge_index, data.edge_type)\n",
    "    loss = F.nll_loss(out[data.train_idx], data.train_y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    pred = model(data.edge_index, data.edge_type).argmax(dim=-1)\n",
    "    train_acc = float((pred[data.train_idx] == data.train_y).float().mean())\n",
    "    test_acc = float((pred[data.test_idx] == data.test_y).float().mean())\n",
    "    return train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96462448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 0.6936, Train: 0.6103 Test: 0.6618\n",
      "Epoch: 02, Loss: 0.5982, Train: 0.9963 Test: 0.6471\n",
      "Epoch: 03, Loss: 0.2604, Train: 1.0000 Test: 0.5882\n",
      "Epoch: 04, Loss: 0.1353, Train: 1.0000 Test: 0.6029\n",
      "Epoch: 05, Loss: 0.0548, Train: 1.0000 Test: 0.6324\n",
      "Epoch: 06, Loss: 0.0212, Train: 1.0000 Test: 0.6912\n",
      "Epoch: 07, Loss: 0.0093, Train: 1.0000 Test: 0.7206\n",
      "Epoch: 08, Loss: 0.0048, Train: 1.0000 Test: 0.7500\n",
      "Epoch: 09, Loss: 0.0029, Train: 1.0000 Test: 0.7794\n",
      "Median time per epoch: 0.0226s\n"
     ]
    }
   ],
   "source": [
    "times = []\n",
    "for epoch in range(1, 10):\n",
    "    start = time.time()\n",
    "    loss = train()\n",
    "    train_acc, test_acc = test()\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Train: {train_acc:.4f} '\n",
    "          f'Test: {test_acc:.4f}')\n",
    "    times.append(time.time() - start)\n",
    "print(f\"Median time per epoch: {torch.tensor(times).median():.4f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb3bddb-c71c-44f5-a1f0-40671ea155ed",
   "metadata": {},
   "source": [
    "### Assignment 2. Given the WordNet18 dataset from Torch Geometric.\n",
    "\n",
    "Questions: \n",
    "\n",
    "1) Show the number of entities, relations, and triplets.\n",
    "2) Load the dataset and construct the TransE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c296d537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/villmow/datasets_knowledge_embedding/master/WN18/original/train.txt\n",
      "Downloading https://raw.githubusercontent.com/villmow/datasets_knowledge_embedding/master/WN18/original/valid.txt\n",
      "Downloading https://raw.githubusercontent.com/villmow/datasets_knowledge_embedding/master/WN18/original/test.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entities: 40943\n",
      "Number of relations: 18\n",
      "Number of triplets: 151442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import WordNet18\n",
    "\n",
    "dataset = WordNet18(root='./data/WordNet18')\n",
    "data = dataset[0]\n",
    "\n",
    "num_entities = data.num_nodes\n",
    "num_relations = len(data.edge_type.unique())\n",
    "num_triplets = data.edge_index.size(1)\n",
    "\n",
    "print(f\"Number of entities: {num_entities}\")\n",
    "print(f\"Number of relations: {num_relations}\")\n",
    "print(f\"Number of triplets: {num_triplets}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcd9be9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch_geometric.nn import RotatE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f97cea4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "from torch_geometric.nn.kge import KGEModel\n",
    "\n",
    "\n",
    "class TransE(KGEModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_nodes: int,\n",
    "        num_relations: int,\n",
    "        hidden_channels: int,\n",
    "        margin: float = 1.0,\n",
    "        p_norm: float = 1.0,\n",
    "        sparse: bool = False,\n",
    "    ):\n",
    "        super().__init__(num_nodes, num_relations, hidden_channels, sparse)\n",
    "\n",
    "        self.p_norm = p_norm\n",
    "        self.margin = margin\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        bound = 6. / math.sqrt(self.hidden_channels)\n",
    "        torch.nn.init.uniform_(self.node_emb.weight, -bound, bound)\n",
    "        torch.nn.init.uniform_(self.rel_emb.weight, -bound, bound)\n",
    "        F.normalize(self.rel_emb.weight.data, p=self.p_norm, dim=-1,\n",
    "                    out=self.rel_emb.weight.data)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        head_index: Tensor,\n",
    "        rel_type: Tensor,\n",
    "        tail_index: Tensor,\n",
    "    ) -> Tensor:\n",
    "\n",
    "        head = self.node_emb(head_index)\n",
    "        rel = self.rel_emb(rel_type)\n",
    "        tail = self.node_emb(tail_index)\n",
    "\n",
    "        head = F.normalize(head, p=self.p_norm, dim=-1)\n",
    "        tail = F.normalize(tail, p=self.p_norm, dim=-1)\n",
    "\n",
    "        # Calculate *negative* TransE norm:\n",
    "        return -((head + rel) - tail).norm(p=self.p_norm, dim=-1)\n",
    "\n",
    "    def loss(\n",
    "        self,\n",
    "        head_index: Tensor,\n",
    "        rel_type: Tensor,\n",
    "        tail_index: Tensor,\n",
    "    ) -> Tensor:\n",
    "\n",
    "        pos_score = self(head_index, rel_type, tail_index)\n",
    "        neg_score = self(*self.random_sample(head_index, rel_type, tail_index))\n",
    "\n",
    "        return F.margin_ranking_loss(\n",
    "            pos_score,\n",
    "            neg_score,\n",
    "            target=torch.ones_like(pos_score),\n",
    "            margin=self.margin,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01af5b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_map = {\n",
    "    'transe': TransE,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6e9d9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model', choices=model_map.keys(), type=str.lower, required=False)\n",
    "parser.add_argument(\"-f\", required=False, help=\"Dummy argument to prevent Jupyter errors.\")\n",
    "args = parser.parse_args([])\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "path = osp.join('data', 'WordNet18')\n",
    "\n",
    "dataset = WordNet18(path)\n",
    "data = dataset[0].to(device)\n",
    "\n",
    "num_edges = data.edge_index.size(1)\n",
    "num_train = int(0.8 * num_edges)\n",
    "num_val = int(0.1 * num_edges)\n",
    "num_test = num_edges - num_train - num_val\n",
    "\n",
    "indices = torch.randperm(num_edges)\n",
    "train_indices = indices[:num_train]\n",
    "val_indices = indices[num_train:num_train + num_val]\n",
    "test_indices = indices[num_train + num_val:]\n",
    "\n",
    "train_data = Data(edge_index=data.edge_index[:, train_indices], edge_type=data.edge_type[train_indices], num_nodes=data.num_nodes).to(device)\n",
    "val_data = Data(edge_index=data.edge_index[:, val_indices], edge_type=data.edge_type[val_indices], num_nodes=data.num_nodes).to(device)\n",
    "test_data = Data(edge_index=data.edge_index[:, test_indices], edge_type=data.edge_type[test_indices], num_nodes=data.num_nodes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9f9c5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arg_map = {'rotate': {'margin': 9.0}}\n",
    "args.model = \"transe\"\n",
    "model = model_map[args.model](\n",
    "    num_nodes=train_data.num_nodes,\n",
    "    num_relations=train_data.num_edge_types,\n",
    "    hidden_channels=50,\n",
    "    **model_arg_map.get(args.model, {}),\n",
    ").to(device)\n",
    "\n",
    "loader = model.loader(\n",
    "    head_index=train_data.edge_index[0],\n",
    "    rel_type=train_data.edge_type,\n",
    "    tail_index=train_data.edge_index[1],\n",
    "    batch_size=1000,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2de01f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_map = {\n",
    "    'transe': optim.Adam(model.parameters(), lr=0.01),\n",
    "    'rotate': optim.Adam(model.parameters(), lr=1e-3),\n",
    "}\n",
    "optimizer = optimizer_map[args.model]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ef16008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = total_examples = 0\n",
    "    for head_index, rel_type, tail_index in loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(head_index, rel_type, tail_index)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * head_index.numel()\n",
    "        total_examples += head_index.numel()\n",
    "    return total_loss / total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "910932c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.9410\n",
      "Epoch: 002, Loss: 0.8186\n",
      "Epoch: 003, Loss: 0.7371\n",
      "Epoch: 004, Loss: 0.6799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15145/15145 [01:20<00:00, 187.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Mean Rank: 13873.97, Test MRR: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    return model.test(\n",
    "        head_index=data.edge_index[0],\n",
    "        rel_type=data.edge_type,\n",
    "        tail_index=data.edge_index[1],\n",
    "        batch_size=20000,\n",
    "        k=10,\n",
    "    )\n",
    "\n",
    "for epoch in range(1, 5):\n",
    "    loss = train()\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "    if epoch % 25 == 0:\n",
    "        rank, mrr, _ = test(val_data)\n",
    "        print(f'Epoch: {epoch:03d}, Val Mean Rank: {rank:.2f}, Val MRR: {mrr:.4f}')\n",
    "\n",
    "rank, mrr, _ = test(test_data)\n",
    "print(f'Test Mean Rank: {rank:.2f}, Test MRR: {mrr:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
