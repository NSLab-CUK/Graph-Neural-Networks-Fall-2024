{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "752c9e04",
   "metadata": {},
   "source": [
    "# 1. Read Tox21 from MoleculeNet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ede28810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES String: CCN1C(=O)NC(c2ccccc2)C1=O\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import MoleculeNet\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw, AllChem\n",
    "import matplotlib.pyplot as plt\n",
    "import py3Dmol\n",
    "\n",
    "# Load MoleculeNet dataset\n",
    "dataset = MoleculeNet(root=\"data/MoleculeNet\", name=\"Tox21\")\n",
    "\n",
    "# Extract the SMILES strings from the dataset (Tox21 contains SMILES in `smiles` attribute)\n",
    "smiles_list = dataset.data.smiles  # SMILES strings are typically in this field\n",
    "\n",
    "# Process the first molecule\n",
    "example_index = 1\n",
    "smiles = smiles_list[example_index]\n",
    "print(f\"SMILES String: {smiles}\")\n",
    "\n",
    "# Convert SMILES to RDKit molecule\n",
    "mol = Chem.MolFromSmiles(smiles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f44e3c",
   "metadata": {},
   "source": [
    "# 1. 2D/3D Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "89b0eacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/3dmoljs_load.v0": "<div id=\"3dmolviewer_17327373856666596\"  style=\"position: relative; width: 400px; height: 400px;\">\n        <p id=\"3dmolwarning_17327373856666596\" style=\"background-color:#ffcccc;color:black\">3Dmol.js failed to load for some reason.  Please check your browser console for error messages.<br></p>\n        </div>\n<script>\n\nvar loadScriptAsync = function(uri){\n  return new Promise((resolve, reject) => {\n    //this is to ignore the existence of requirejs amd\n    var savedexports, savedmodule;\n    if (typeof exports !== 'undefined') savedexports = exports;\n    else exports = {}\n    if (typeof module !== 'undefined') savedmodule = module;\n    else module = {}\n\n    var tag = document.createElement('script');\n    tag.src = uri;\n    tag.async = true;\n    tag.onload = () => {\n        exports = savedexports;\n        module = savedmodule;\n        resolve();\n    };\n  var firstScriptTag = document.getElementsByTagName('script')[0];\n  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n});\n};\n\nif(typeof $3Dmolpromise === 'undefined') {\n$3Dmolpromise = null;\n  $3Dmolpromise = loadScriptAsync('https://cdnjs.cloudflare.com/ajax/libs/3Dmol/2.4.2/3Dmol-min.js');\n}\n\nvar viewer_17327373856666596 = null;\nvar warn = document.getElementById(\"3dmolwarning_17327373856666596\");\nif(warn) {\n    warn.parentNode.removeChild(warn);\n}\n$3Dmolpromise.then(function() {\nviewer_17327373856666596 = $3Dmol.createViewer(document.getElementById(\"3dmolviewer_17327373856666596\"),{backgroundColor:\"white\"});\nviewer_17327373856666596.zoomTo();\n\tviewer_17327373856666596.addModel(\"\\n     RDKit          3D\\n\\n 27 28  0  0  0  0  0  0  0  0999 V2000\\n   -4.0505    0.4686    0.3836 C   0  0  0  0  0  0  0  0  0  0  0  0\\n   -3.3516    0.0603   -0.8947 C   0  0  0  0  0  0  0  0  0  0  0  0\\n   -1.9832   -0.3265   -0.6097 N   0  0  0  0  0  0  0  0  0  0  0  0\\n   -1.5809   -1.6538   -0.2882 C   0  0  0  0  0  0  0  0  0  0  0  0\\n   -2.3085   -2.6869   -0.1970 O   0  0  0  0  0  0  0  0  0  0  0  0\\n   -0.1735   -1.5751   -0.0885 N   0  0  0  0  0  0  0  0  0  0  0  0\\n    0.3434   -0.3556   -0.7357 C   0  0  0  0  0  0  0  0  0  0  0  0\\n    1.6013    0.0800   -0.1530 C   0  0  0  0  0  0  0  0  0  0  0  0\\n    2.5628   -0.9095    0.1090 C   0  0  0  0  0  0  0  0  0  0  0  0\\n    3.7875   -0.5951    0.6589 C   0  0  0  0  0  0  0  0  0  0  0  0\\n    4.1238    0.7022    0.9763 C   0  0  0  0  0  0  0  0  0  0  0  0\\n    3.1895    1.6853    0.7246 C   0  0  0  0  0  0  0  0  0  0  0  0\\n    1.9617    1.3584    0.1716 C   0  0  0  0  0  0  0  0  0  0  0  0\\n   -0.8113    0.5228   -0.5970 C   0  0  0  0  0  0  0  0  0  0  0  0\\n   -0.9347    1.7680   -0.4810 O   0  0  0  0  0  0  0  0  0  0  0  0\\n   -3.7797    1.5144    0.6254 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -5.1620    0.3347    0.2707 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -3.7221   -0.1472    1.2501 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -3.9255   -0.7340   -1.3714 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -3.3606    0.9255   -1.5964 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    0.3965   -2.2779    0.4371 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    0.4812   -0.6042   -1.8101 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    2.3691   -1.9551   -0.1148 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    4.5143   -1.3744    0.8526 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    5.0978    0.8911    1.4053 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    3.4345    2.7305    0.9696 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    1.2807    2.1536   -0.0027 H   0  0  0  0  0  0  0  0  0  0  0  0\\n  1  2  1  0\\n  2  3  1  0\\n  3  4  1  0\\n  4  5  2  0\\n  4  6  1  0\\n  6  7  1  0\\n  7  8  1  0\\n  8  9  2  0\\n  9 10  1  0\\n 10 11  2  0\\n 11 12  1  0\\n 12 13  2  0\\n  7 14  1  0\\n 14 15  2  0\\n 14  3  1  0\\n 13  8  1  0\\n  1 16  1  0\\n  1 17  1  0\\n  1 18  1  0\\n  2 19  1  0\\n  2 20  1  0\\n  6 21  1  0\\n  7 22  1  0\\n  9 23  1  0\\n 10 24  1  0\\n 11 25  1  0\\n 12 26  1  0\\n 13 27  1  0\\nM  END\\n\",\"mol\");\n\tviewer_17327373856666596.setStyle({\"stick\": {}});\n\tviewer_17327373856666596.zoomTo();\nviewer_17327373856666596.render();\n});\n</script>",
      "text/html": [
       "<div id=\"3dmolviewer_17327373856666596\"  style=\"position: relative; width: 400px; height: 400px;\">\n",
       "        <p id=\"3dmolwarning_17327373856666596\" style=\"background-color:#ffcccc;color:black\">3Dmol.js failed to load for some reason.  Please check your browser console for error messages.<br></p>\n",
       "        </div>\n",
       "<script>\n",
       "\n",
       "var loadScriptAsync = function(uri){\n",
       "  return new Promise((resolve, reject) => {\n",
       "    //this is to ignore the existence of requirejs amd\n",
       "    var savedexports, savedmodule;\n",
       "    if (typeof exports !== 'undefined') savedexports = exports;\n",
       "    else exports = {}\n",
       "    if (typeof module !== 'undefined') savedmodule = module;\n",
       "    else module = {}\n",
       "\n",
       "    var tag = document.createElement('script');\n",
       "    tag.src = uri;\n",
       "    tag.async = true;\n",
       "    tag.onload = () => {\n",
       "        exports = savedexports;\n",
       "        module = savedmodule;\n",
       "        resolve();\n",
       "    };\n",
       "  var firstScriptTag = document.getElementsByTagName('script')[0];\n",
       "  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n",
       "});\n",
       "};\n",
       "\n",
       "if(typeof $3Dmolpromise === 'undefined') {\n",
       "$3Dmolpromise = null;\n",
       "  $3Dmolpromise = loadScriptAsync('https://cdnjs.cloudflare.com/ajax/libs/3Dmol/2.4.2/3Dmol-min.js');\n",
       "}\n",
       "\n",
       "var viewer_17327373856666596 = null;\n",
       "var warn = document.getElementById(\"3dmolwarning_17327373856666596\");\n",
       "if(warn) {\n",
       "    warn.parentNode.removeChild(warn);\n",
       "}\n",
       "$3Dmolpromise.then(function() {\n",
       "viewer_17327373856666596 = $3Dmol.createViewer(document.getElementById(\"3dmolviewer_17327373856666596\"),{backgroundColor:\"white\"});\n",
       "viewer_17327373856666596.zoomTo();\n",
       "\tviewer_17327373856666596.addModel(\"\\n     RDKit          3D\\n\\n 27 28  0  0  0  0  0  0  0  0999 V2000\\n   -4.0505    0.4686    0.3836 C   0  0  0  0  0  0  0  0  0  0  0  0\\n   -3.3516    0.0603   -0.8947 C   0  0  0  0  0  0  0  0  0  0  0  0\\n   -1.9832   -0.3265   -0.6097 N   0  0  0  0  0  0  0  0  0  0  0  0\\n   -1.5809   -1.6538   -0.2882 C   0  0  0  0  0  0  0  0  0  0  0  0\\n   -2.3085   -2.6869   -0.1970 O   0  0  0  0  0  0  0  0  0  0  0  0\\n   -0.1735   -1.5751   -0.0885 N   0  0  0  0  0  0  0  0  0  0  0  0\\n    0.3434   -0.3556   -0.7357 C   0  0  0  0  0  0  0  0  0  0  0  0\\n    1.6013    0.0800   -0.1530 C   0  0  0  0  0  0  0  0  0  0  0  0\\n    2.5628   -0.9095    0.1090 C   0  0  0  0  0  0  0  0  0  0  0  0\\n    3.7875   -0.5951    0.6589 C   0  0  0  0  0  0  0  0  0  0  0  0\\n    4.1238    0.7022    0.9763 C   0  0  0  0  0  0  0  0  0  0  0  0\\n    3.1895    1.6853    0.7246 C   0  0  0  0  0  0  0  0  0  0  0  0\\n    1.9617    1.3584    0.1716 C   0  0  0  0  0  0  0  0  0  0  0  0\\n   -0.8113    0.5228   -0.5970 C   0  0  0  0  0  0  0  0  0  0  0  0\\n   -0.9347    1.7680   -0.4810 O   0  0  0  0  0  0  0  0  0  0  0  0\\n   -3.7797    1.5144    0.6254 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -5.1620    0.3347    0.2707 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -3.7221   -0.1472    1.2501 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -3.9255   -0.7340   -1.3714 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -3.3606    0.9255   -1.5964 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    0.3965   -2.2779    0.4371 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    0.4812   -0.6042   -1.8101 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    2.3691   -1.9551   -0.1148 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    4.5143   -1.3744    0.8526 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    5.0978    0.8911    1.4053 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    3.4345    2.7305    0.9696 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    1.2807    2.1536   -0.0027 H   0  0  0  0  0  0  0  0  0  0  0  0\\n  1  2  1  0\\n  2  3  1  0\\n  3  4  1  0\\n  4  5  2  0\\n  4  6  1  0\\n  6  7  1  0\\n  7  8  1  0\\n  8  9  2  0\\n  9 10  1  0\\n 10 11  2  0\\n 11 12  1  0\\n 12 13  2  0\\n  7 14  1  0\\n 14 15  2  0\\n 14  3  1  0\\n 13  8  1  0\\n  1 16  1  0\\n  1 17  1  0\\n  1 18  1  0\\n  2 19  1  0\\n  2 20  1  0\\n  6 21  1  0\\n  7 22  1  0\\n  9 23  1  0\\n 10 24  1  0\\n 11 25  1  0\\n 12 26  1  0\\n 13 27  1  0\\nM  END\\n\",\"mol\");\n",
       "\tviewer_17327373856666596.setStyle({\"stick\": {}});\n",
       "\tviewer_17327373856666596.zoomTo();\n",
       "viewer_17327373856666596.render();\n",
       "});\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate 2D Coordinates\n",
    "AllChem.Compute2DCoords(mol)\n",
    "\n",
    "# Visualize as a 2D Molecule\n",
    "img = Draw.MolToImage(mol, size=(300, 300))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Generate 3D Coordinates\n",
    "mol_3d = Chem.AddHs(mol)  # Add hydrogens for 3D structure\n",
    "AllChem.EmbedMolecule(mol_3d, AllChem.ETKDG())  # Generate 3D conformation\n",
    "\n",
    "# Visualize as a 3D Molecule using py3Dmol\n",
    "block = Chem.MolToMolBlock(mol_3d)\n",
    "view = py3Dmol.view(width=400, height=400)\n",
    "view.addModel(block, \"mol\")  # Add the molecule\n",
    "view.setStyle({\"stick\": {}})  # Style as sticks\n",
    "view.zoomTo()  # Zoom to fit\n",
    "view.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1660a15b",
   "metadata": {},
   "source": [
    "# 3. GCN classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3731a7",
   "metadata": {},
   "source": [
    "## 3.1. Analysis dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "086e6426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Tox21(7831)\n",
      "Number of graphs: 7831\n",
      "Number of features: 9\n",
      "Number of classes: 12\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.datasets import MoleculeNet\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Load MoleculeNet dataset (Tox21)\n",
    "dataset = MoleculeNet(root=\"data/MoleculeNet\", name=\"Tox21\")\n",
    "print(f\"Dataset: {dataset}\")\n",
    "print(f\"Number of graphs: {len(dataset)}\")\n",
    "print(f\"Number of features: {dataset.num_node_features}\")\n",
    "print(f\"Number of classes: {dataset.num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8c7ad7",
   "metadata": {},
   "source": [
    "## 3.2. Split train/validation/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "829d97d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train, validation, and test sets\n",
    "torch.manual_seed(42)\n",
    "train_dataset = dataset[:int(len(dataset) * 0.8)]\n",
    "val_dataset = dataset[int(len(dataset) * 0.8):int(len(dataset) * 0.9)]\n",
    "test_dataset = dataset[int(len(dataset) * 0.9):]\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb505c5",
   "metadata": {},
   "source": [
    "## 3.3. GCN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "35284b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=2, dropout=0.5):\n",
    "        super(GCN, self).__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.batch_norms = torch.nn.ModuleList()\n",
    "        \n",
    "        # Input layer\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels))\n",
    "        self.batch_norms.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        \n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.convs.append(GCNConv(hidden_channels, hidden_channels))\n",
    "            self.batch_norms.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc = Linear(hidden_channels, out_channels)\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "    \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # Apply GCN layers\n",
    "        for conv, batch_norm in zip(self.convs, self.batch_norms):\n",
    "            x = conv(x, edge_index)\n",
    "            x = batch_norm(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "        \n",
    "        # Global pooling\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1604e087",
   "metadata": {},
   "source": [
    "## 3.4. Train, Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3ab9c0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Train Loss: 0.3318, Val Loss: 0.2356, Val ROC-AUC: 0.7463\n",
      "Epoch: 02, Train Loss: 0.2378, Val Loss: 0.2284, Val ROC-AUC: 0.7548\n",
      "Epoch: 03, Train Loss: 0.2331, Val Loss: 0.2217, Val ROC-AUC: 0.7657\n",
      "Epoch: 04, Train Loss: 0.2310, Val Loss: 0.2239, Val ROC-AUC: 0.7650\n",
      "Epoch: 05, Train Loss: 0.2279, Val Loss: 0.2243, Val ROC-AUC: 0.7608\n",
      "Epoch: 06, Train Loss: 0.2272, Val Loss: 0.2207, Val ROC-AUC: 0.7725\n",
      "Epoch: 07, Train Loss: 0.2265, Val Loss: 0.2200, Val ROC-AUC: 0.7702\n",
      "Epoch: 08, Train Loss: 0.2251, Val Loss: 0.2168, Val ROC-AUC: 0.7816\n",
      "Epoch: 09, Train Loss: 0.2252, Val Loss: 0.2202, Val ROC-AUC: 0.7726\n",
      "Epoch: 10, Train Loss: 0.2231, Val Loss: 0.2170, Val ROC-AUC: 0.7804\n",
      "Epoch: 11, Train Loss: 0.2226, Val Loss: 0.2173, Val ROC-AUC: 0.7799\n",
      "Epoch: 12, Train Loss: 0.2216, Val Loss: 0.2187, Val ROC-AUC: 0.7790\n",
      "Epoch: 13, Train Loss: 0.2208, Val Loss: 0.2178, Val ROC-AUC: 0.7804\n",
      "Epoch: 14, Train Loss: 0.2213, Val Loss: 0.2163, Val ROC-AUC: 0.7854\n",
      "Epoch: 15, Train Loss: 0.2224, Val Loss: 0.2166, Val ROC-AUC: 0.7780\n",
      "Epoch: 16, Train Loss: 0.2202, Val Loss: 0.2186, Val ROC-AUC: 0.7738\n",
      "Epoch: 17, Train Loss: 0.2195, Val Loss: 0.2158, Val ROC-AUC: 0.7818\n",
      "Epoch: 18, Train Loss: 0.2198, Val Loss: 0.2158, Val ROC-AUC: 0.7867\n",
      "Epoch: 19, Train Loss: 0.2194, Val Loss: 0.2169, Val ROC-AUC: 0.7852\n",
      "Epoch: 20, Train Loss: 0.2198, Val Loss: 0.2154, Val ROC-AUC: 0.7854\n",
      "Epoch: 21, Train Loss: 0.2180, Val Loss: 0.2167, Val ROC-AUC: 0.7828\n",
      "Epoch: 22, Train Loss: 0.2187, Val Loss: 0.2120, Val ROC-AUC: 0.7926\n",
      "Epoch: 23, Train Loss: 0.2178, Val Loss: 0.2136, Val ROC-AUC: 0.7880\n",
      "Epoch: 24, Train Loss: 0.2167, Val Loss: 0.2148, Val ROC-AUC: 0.7936\n",
      "Epoch: 25, Train Loss: 0.2176, Val Loss: 0.2156, Val ROC-AUC: 0.7830\n",
      "Epoch: 26, Train Loss: 0.2163, Val Loss: 0.2141, Val ROC-AUC: 0.7963\n",
      "Epoch: 27, Train Loss: 0.2169, Val Loss: 0.2122, Val ROC-AUC: 0.7918\n",
      "Epoch: 28, Train Loss: 0.2181, Val Loss: 0.2120, Val ROC-AUC: 0.7901\n",
      "Epoch: 29, Train Loss: 0.2167, Val Loss: 0.2112, Val ROC-AUC: 0.7944\n",
      "Epoch: 30, Train Loss: 0.2152, Val Loss: 0.2122, Val ROC-AUC: 0.7918\n",
      "Test Loss: 0.2181, Test ROC-AUC: 0.8151\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model, optimizer, and loss function\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GCN(\n",
    "    in_channels=dataset.num_node_features,\n",
    "    hidden_channels=64,\n",
    "    out_channels=dataset.num_classes,\n",
    "    num_layers=3,\n",
    "    dropout=0.5\n",
    ").to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Training function\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        data.x = data.x.float()\n",
    "        data.y = data.y.float()\n",
    "        \n",
    "        # Mask valid labels (non-NaN)\n",
    "        mask = ~torch.isnan(data.y)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(out[mask], data.y[mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            data.x = data.x.float()\n",
    "            data.y = data.y.float()\n",
    "            \n",
    "            # Mask valid labels (non-NaN)\n",
    "            mask = ~torch.isnan(data.y)\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "            loss = criterion(out[mask], data.y[mask])\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            y_true.append(data.y[mask].cpu())\n",
    "            y_pred.append(out[mask].cpu())\n",
    "    \n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    \n",
    "    # Compute ROC-AUC\n",
    "    roc_auc = roc_auc_score(y_true.numpy(), y_pred.sigmoid().numpy(), average=\"macro\")\n",
    "    return total_loss / len(loader), roc_auc\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, 31):\n",
    "    train_loss = train()\n",
    "    val_loss, val_roc_auc = evaluate(val_loader)\n",
    "    print(f\"Epoch: {epoch:02d}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val ROC-AUC: {val_roc_auc:.4f}\")\n",
    "\n",
    "# Test the model\n",
    "test_loss, test_roc_auc = evaluate(test_loader)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test ROC-AUC: {test_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e760d1a7",
   "metadata": {},
   "source": [
    "## 4. GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e4423b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv, global_mean_pool\n",
    "from torch_geometric.datasets import MoleculeNet\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Define the GraphSAGE model\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=2, dropout=0.5):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.batch_norms = torch.nn.ModuleList()\n",
    "        \n",
    "        # Input layer\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        self.batch_norms.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        \n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "            self.batch_norms.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc = Linear(hidden_channels, out_channels)\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "    \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # Apply GraphSAGE layers\n",
    "        for conv, batch_norm in zip(self.convs, self.batch_norms):\n",
    "            x = conv(x, edge_index)\n",
    "            x = batch_norm(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "        \n",
    "        # Global pooling\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5dd2d370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Train Loss: 0.3350, Val Loss: 0.2347, Val ROC-AUC: 0.7308\n",
      "Epoch: 02, Train Loss: 0.2358, Val Loss: 0.2268, Val ROC-AUC: 0.7502\n",
      "Epoch: 03, Train Loss: 0.2326, Val Loss: 0.2260, Val ROC-AUC: 0.7506\n",
      "Epoch: 04, Train Loss: 0.2296, Val Loss: 0.2207, Val ROC-AUC: 0.7695\n",
      "Epoch: 05, Train Loss: 0.2279, Val Loss: 0.2199, Val ROC-AUC: 0.7703\n",
      "Epoch: 06, Train Loss: 0.2258, Val Loss: 0.2217, Val ROC-AUC: 0.7705\n",
      "Epoch: 07, Train Loss: 0.2241, Val Loss: 0.2162, Val ROC-AUC: 0.7838\n",
      "Epoch: 08, Train Loss: 0.2238, Val Loss: 0.2178, Val ROC-AUC: 0.7735\n",
      "Epoch: 09, Train Loss: 0.2211, Val Loss: 0.2170, Val ROC-AUC: 0.7809\n",
      "Epoch: 10, Train Loss: 0.2205, Val Loss: 0.2166, Val ROC-AUC: 0.7811\n",
      "Epoch: 11, Train Loss: 0.2199, Val Loss: 0.2137, Val ROC-AUC: 0.7868\n",
      "Epoch: 12, Train Loss: 0.2184, Val Loss: 0.2135, Val ROC-AUC: 0.7903\n",
      "Epoch: 13, Train Loss: 0.2189, Val Loss: 0.2152, Val ROC-AUC: 0.7817\n",
      "Epoch: 14, Train Loss: 0.2171, Val Loss: 0.2193, Val ROC-AUC: 0.7862\n",
      "Epoch: 15, Train Loss: 0.2168, Val Loss: 0.2143, Val ROC-AUC: 0.7895\n",
      "Epoch: 16, Train Loss: 0.2157, Val Loss: 0.2123, Val ROC-AUC: 0.7918\n",
      "Epoch: 17, Train Loss: 0.2160, Val Loss: 0.2128, Val ROC-AUC: 0.7923\n",
      "Epoch: 18, Train Loss: 0.2160, Val Loss: 0.2121, Val ROC-AUC: 0.7977\n",
      "Epoch: 19, Train Loss: 0.2152, Val Loss: 0.2113, Val ROC-AUC: 0.7974\n",
      "Epoch: 20, Train Loss: 0.2155, Val Loss: 0.2133, Val ROC-AUC: 0.7860\n",
      "Epoch: 21, Train Loss: 0.2141, Val Loss: 0.2118, Val ROC-AUC: 0.7945\n",
      "Epoch: 22, Train Loss: 0.2135, Val Loss: 0.2111, Val ROC-AUC: 0.7976\n",
      "Epoch: 23, Train Loss: 0.2139, Val Loss: 0.2113, Val ROC-AUC: 0.7951\n",
      "Epoch: 24, Train Loss: 0.2125, Val Loss: 0.2092, Val ROC-AUC: 0.8027\n",
      "Epoch: 25, Train Loss: 0.2115, Val Loss: 0.2085, Val ROC-AUC: 0.8079\n",
      "Epoch: 26, Train Loss: 0.2127, Val Loss: 0.2110, Val ROC-AUC: 0.8002\n",
      "Epoch: 27, Train Loss: 0.2117, Val Loss: 0.2091, Val ROC-AUC: 0.8038\n",
      "Epoch: 28, Train Loss: 0.2109, Val Loss: 0.2114, Val ROC-AUC: 0.8030\n",
      "Epoch: 29, Train Loss: 0.2103, Val Loss: 0.2106, Val ROC-AUC: 0.8019\n",
      "Epoch: 30, Train Loss: 0.2110, Val Loss: 0.2103, Val ROC-AUC: 0.8025\n",
      "Test Loss: 0.2161, Test ROC-AUC: 0.8222\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model, optimizer, and loss function\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GraphSAGE(\n",
    "    in_channels=dataset.num_node_features,\n",
    "    hidden_channels=64,\n",
    "    out_channels=dataset.num_classes,\n",
    "    num_layers=3,\n",
    "    dropout=0.5\n",
    ").to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Training function\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        data.x = data.x.float()\n",
    "        data.y = data.y.float()\n",
    "        \n",
    "        # Mask valid labels (non-NaN)\n",
    "        mask = ~torch.isnan(data.y)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(out[mask], data.y[mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            data.x = data.x.float()\n",
    "            data.y = data.y.float()\n",
    "            \n",
    "            # Mask valid labels (non-NaN)\n",
    "            mask = ~torch.isnan(data.y)\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "            loss = criterion(out[mask], data.y[mask])\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            y_true.append(data.y[mask].cpu())\n",
    "            y_pred.append(out[mask].cpu())\n",
    "    \n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    \n",
    "    # Compute ROC-AUC\n",
    "    roc_auc = roc_auc_score(y_true.numpy(), y_pred.sigmoid().numpy(), average=\"macro\")\n",
    "    return total_loss / len(loader), roc_auc\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, 31):\n",
    "    train_loss = train()\n",
    "    val_loss, val_roc_auc = evaluate(val_loader)\n",
    "    print(f\"Epoch: {epoch:02d}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val ROC-AUC: {val_roc_auc:.4f}\")\n",
    "\n",
    "# Test the model\n",
    "test_loss, test_roc_auc = evaluate(test_loader)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test ROC-AUC: {test_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c971c32",
   "metadata": {},
   "source": [
    "## 5. GIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7a956d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GINConv, global_mean_pool\n",
    "from torch_geometric.datasets import MoleculeNet\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Define the GIN model\n",
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=2, dropout=0.5):\n",
    "        super(GIN, self).__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.batch_norms = torch.nn.ModuleList()\n",
    "        \n",
    "        # Input layer\n",
    "        self.convs.append(\n",
    "            GINConv(\n",
    "                torch.nn.Sequential(\n",
    "                    Linear(in_channels, hidden_channels),\n",
    "                    torch.nn.ReLU(),\n",
    "                    Linear(hidden_channels, hidden_channels)\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        self.batch_norms.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        \n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.convs.append(\n",
    "                GINConv(\n",
    "                    torch.nn.Sequential(\n",
    "                        Linear(hidden_channels, hidden_channels),\n",
    "                        torch.nn.ReLU(),\n",
    "                        Linear(hidden_channels, hidden_channels)\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            self.batch_norms.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc = Linear(hidden_channels, out_channels)\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "    \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # Apply GIN layers\n",
    "        for conv, batch_norm in zip(self.convs, self.batch_norms):\n",
    "            x = conv(x, edge_index)\n",
    "            x = batch_norm(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "        \n",
    "        # Global pooling\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "78dd09ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Train Loss: 0.3079, Val Loss: 0.2352, Val ROC-AUC: 0.7406\n",
      "Epoch: 02, Train Loss: 0.2330, Val Loss: 0.2278, Val ROC-AUC: 0.7802\n",
      "Epoch: 03, Train Loss: 0.2272, Val Loss: 0.2399, Val ROC-AUC: 0.7685\n",
      "Epoch: 04, Train Loss: 0.2254, Val Loss: 0.2964, Val ROC-AUC: 0.7137\n",
      "Epoch: 05, Train Loss: 0.2247, Val Loss: 0.2340, Val ROC-AUC: 0.7479\n",
      "Epoch: 06, Train Loss: 0.2232, Val Loss: 0.2307, Val ROC-AUC: 0.7758\n",
      "Epoch: 07, Train Loss: 0.2218, Val Loss: 0.2172, Val ROC-AUC: 0.7795\n",
      "Epoch: 08, Train Loss: 0.2211, Val Loss: 0.2167, Val ROC-AUC: 0.7820\n",
      "Epoch: 09, Train Loss: 0.2208, Val Loss: 0.2228, Val ROC-AUC: 0.7925\n",
      "Epoch: 10, Train Loss: 0.2202, Val Loss: 0.2419, Val ROC-AUC: 0.7852\n",
      "Epoch: 11, Train Loss: 0.2187, Val Loss: 0.2195, Val ROC-AUC: 0.7790\n",
      "Epoch: 12, Train Loss: 0.2185, Val Loss: 0.2197, Val ROC-AUC: 0.7790\n",
      "Epoch: 13, Train Loss: 0.2172, Val Loss: 0.2244, Val ROC-AUC: 0.7956\n",
      "Epoch: 14, Train Loss: 0.2172, Val Loss: 0.2117, Val ROC-AUC: 0.7944\n",
      "Epoch: 15, Train Loss: 0.2166, Val Loss: 0.2140, Val ROC-AUC: 0.7898\n",
      "Epoch: 16, Train Loss: 0.2155, Val Loss: 0.2240, Val ROC-AUC: 0.7875\n",
      "Epoch: 17, Train Loss: 0.2139, Val Loss: 0.2374, Val ROC-AUC: 0.7676\n",
      "Epoch: 18, Train Loss: 0.2140, Val Loss: 0.2251, Val ROC-AUC: 0.7795\n",
      "Epoch: 19, Train Loss: 0.2133, Val Loss: 0.2301, Val ROC-AUC: 0.7763\n",
      "Epoch: 20, Train Loss: 0.2128, Val Loss: 0.2175, Val ROC-AUC: 0.7943\n",
      "Epoch: 21, Train Loss: 0.2114, Val Loss: 0.2171, Val ROC-AUC: 0.7956\n",
      "Epoch: 22, Train Loss: 0.2118, Val Loss: 0.2140, Val ROC-AUC: 0.7883\n",
      "Epoch: 23, Train Loss: 0.2111, Val Loss: 0.2576, Val ROC-AUC: 0.7703\n",
      "Epoch: 24, Train Loss: 0.2112, Val Loss: 0.2131, Val ROC-AUC: 0.7965\n",
      "Epoch: 25, Train Loss: 0.2102, Val Loss: 0.2125, Val ROC-AUC: 0.8075\n",
      "Epoch: 26, Train Loss: 0.2093, Val Loss: 0.2223, Val ROC-AUC: 0.8048\n",
      "Epoch: 27, Train Loss: 0.2087, Val Loss: 0.2168, Val ROC-AUC: 0.8082\n",
      "Epoch: 28, Train Loss: 0.2096, Val Loss: 0.2079, Val ROC-AUC: 0.8039\n",
      "Epoch: 29, Train Loss: 0.2080, Val Loss: 0.2247, Val ROC-AUC: 0.7920\n",
      "Epoch: 30, Train Loss: 0.2079, Val Loss: 0.2269, Val ROC-AUC: 0.7843\n",
      "Test Loss: 0.2283, Test ROC-AUC: 0.8099\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model, optimizer, and loss function\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GIN(\n",
    "    in_channels=dataset.num_node_features,\n",
    "    hidden_channels=64,\n",
    "    out_channels=dataset.num_classes,\n",
    "    num_layers=3,\n",
    "    dropout=0.5\n",
    ").to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Training function\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        data.x = data.x.float()\n",
    "        data.y = data.y.float()\n",
    "        \n",
    "        # Mask valid labels (non-NaN)\n",
    "        mask = ~torch.isnan(data.y)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(out[mask], data.y[mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            data.x = data.x.float()\n",
    "            data.y = data.y.float()\n",
    "            \n",
    "            # Mask valid labels (non-NaN)\n",
    "            mask = ~torch.isnan(data.y)\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "            loss = criterion(out[mask], data.y[mask])\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            y_true.append(data.y[mask].cpu())\n",
    "            y_pred.append(out[mask].cpu())\n",
    "    \n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    \n",
    "    # Compute ROC-AUC\n",
    "    roc_auc = roc_auc_score(y_true.numpy(), y_pred.sigmoid().numpy(), average=\"macro\")\n",
    "    return total_loss / len(loader), roc_auc\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, 31):\n",
    "    train_loss = train()\n",
    "    val_loss, val_roc_auc = evaluate(val_loader)\n",
    "    print(f\"Epoch: {epoch:02d}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val ROC-AUC: {val_roc_auc:.4f}\")\n",
    "\n",
    "# Test the model\n",
    "test_loss, test_roc_auc = evaluate(test_loader)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test ROC-AUC: {test_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e135aa",
   "metadata": {},
   "source": [
    "## 6. GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6382bfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "from torch.nn import Linear, Dropout\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, global_mean_pool\n",
    "from torch_geometric.datasets import MoleculeNet\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Define the GAT model\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_heads=2, dropout=0.3):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads=num_heads)\n",
    "        self.conv2 = GATConv(hidden_channels * num_heads, hidden_channels, heads=num_heads)\n",
    "        self.fc = Linear(hidden_channels * num_heads, out_channels)\n",
    "        self.dropout = Dropout(p=dropout)\n",
    "    \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # GAT layers\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = self.dropout(x)\n",
    "        # Global mean pooling\n",
    "        x = global_mean_pool(x, batch)\n",
    "        # Fully connected layer\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ca8b5914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Train Loss: 0.2690, Val Loss: 0.2372, Val ROC-AUC: 0.7099\n",
      "Epoch: 02, Train Loss: 0.2425, Val Loss: 0.2319, Val ROC-AUC: 0.7434\n",
      "Epoch: 03, Train Loss: 0.2375, Val Loss: 0.2267, Val ROC-AUC: 0.7533\n",
      "Epoch: 04, Train Loss: 0.2344, Val Loss: 0.2262, Val ROC-AUC: 0.7548\n",
      "Epoch: 05, Train Loss: 0.2326, Val Loss: 0.2250, Val ROC-AUC: 0.7568\n",
      "Epoch: 06, Train Loss: 0.2312, Val Loss: 0.2224, Val ROC-AUC: 0.7652\n",
      "Epoch: 07, Train Loss: 0.2300, Val Loss: 0.2225, Val ROC-AUC: 0.7673\n",
      "Epoch: 08, Train Loss: 0.2294, Val Loss: 0.2246, Val ROC-AUC: 0.7546\n",
      "Epoch: 09, Train Loss: 0.2296, Val Loss: 0.2222, Val ROC-AUC: 0.7664\n",
      "Epoch: 10, Train Loss: 0.2276, Val Loss: 0.2304, Val ROC-AUC: 0.7604\n",
      "Epoch: 11, Train Loss: 0.2292, Val Loss: 0.2208, Val ROC-AUC: 0.7679\n",
      "Epoch: 12, Train Loss: 0.2274, Val Loss: 0.2241, Val ROC-AUC: 0.7611\n",
      "Epoch: 13, Train Loss: 0.2276, Val Loss: 0.2286, Val ROC-AUC: 0.7630\n",
      "Epoch: 14, Train Loss: 0.2269, Val Loss: 0.2217, Val ROC-AUC: 0.7666\n",
      "Epoch: 15, Train Loss: 0.2260, Val Loss: 0.2196, Val ROC-AUC: 0.7712\n",
      "Epoch: 16, Train Loss: 0.2267, Val Loss: 0.2209, Val ROC-AUC: 0.7707\n",
      "Epoch: 17, Train Loss: 0.2250, Val Loss: 0.2200, Val ROC-AUC: 0.7727\n",
      "Epoch: 18, Train Loss: 0.2247, Val Loss: 0.2215, Val ROC-AUC: 0.7682\n",
      "Epoch: 19, Train Loss: 0.2243, Val Loss: 0.2202, Val ROC-AUC: 0.7669\n",
      "Epoch: 20, Train Loss: 0.2246, Val Loss: 0.2218, Val ROC-AUC: 0.7738\n",
      "Epoch: 21, Train Loss: 0.2236, Val Loss: 0.2216, Val ROC-AUC: 0.7693\n",
      "Epoch: 22, Train Loss: 0.2232, Val Loss: 0.2207, Val ROC-AUC: 0.7744\n",
      "Epoch: 23, Train Loss: 0.2223, Val Loss: 0.2208, Val ROC-AUC: 0.7725\n",
      "Epoch: 24, Train Loss: 0.2214, Val Loss: 0.2184, Val ROC-AUC: 0.7746\n",
      "Epoch: 25, Train Loss: 0.2217, Val Loss: 0.2189, Val ROC-AUC: 0.7733\n",
      "Epoch: 26, Train Loss: 0.2214, Val Loss: 0.2196, Val ROC-AUC: 0.7768\n",
      "Epoch: 27, Train Loss: 0.2214, Val Loss: 0.2209, Val ROC-AUC: 0.7705\n",
      "Epoch: 28, Train Loss: 0.2203, Val Loss: 0.2195, Val ROC-AUC: 0.7729\n",
      "Epoch: 29, Train Loss: 0.2212, Val Loss: 0.2183, Val ROC-AUC: 0.7822\n",
      "Epoch: 30, Train Loss: 0.2205, Val Loss: 0.2184, Val ROC-AUC: 0.7749\n",
      "Test Loss: 0.2266, Test ROC-AUC: 0.7943\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model, optimizer, and loss function\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GAT(in_channels=dataset.num_node_features, hidden_channels=64, out_channels=dataset.num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Training function\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        data.x = data.x.float()\n",
    "        data.y = data.y.float()\n",
    "        \n",
    "        # Mask valid labels (non-NaN)\n",
    "        mask = ~torch.isnan(data.y)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(out[mask], data.y[mask])  # Only consider valid labels\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            data.x = data.x.float()\n",
    "            data.y = data.y.float()\n",
    "            \n",
    "            # Mask valid labels (non-NaN)\n",
    "            mask = ~torch.isnan(data.y)\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "            loss = criterion(out[mask], data.y[mask])\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            y_true.append(data.y[mask].cpu())\n",
    "            y_pred.append(out[mask].cpu())\n",
    "    \n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    \n",
    "    # Compute ROC-AUC\n",
    "    roc_auc = roc_auc_score(y_true.numpy(), y_pred.sigmoid().numpy(), average=\"macro\")\n",
    "    return total_loss / len(loader), roc_auc\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, 31):\n",
    "    train_loss = train()\n",
    "    val_loss, val_roc_auc = evaluate(val_loader)\n",
    "    print(f\"Epoch: {epoch:02d}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val ROC-AUC: {val_roc_auc:.4f}\")\n",
    "\n",
    "# Test the model\n",
    "test_loss, test_roc_auc = evaluate(test_loader)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test ROC-AUC: {test_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad96a27",
   "metadata": {},
   "source": [
    "## 7. Graph Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "66e560e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import TransformerConv, global_mean_pool\n",
    "from torch_geometric.datasets import MoleculeNet\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Define the Graph Transformer model\n",
    "class GraphTransformer(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_heads=4, num_layers=2, dropout=0.5):\n",
    "        super(GraphTransformer, self).__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.batch_norms = torch.nn.ModuleList()\n",
    "        \n",
    "        # Input layer\n",
    "        self.convs.append(TransformerConv(in_channels, hidden_channels, heads=num_heads, dropout=dropout))\n",
    "        self.batch_norms.append(torch.nn.BatchNorm1d(hidden_channels * num_heads))\n",
    "        \n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.convs.append(TransformerConv(hidden_channels * num_heads, hidden_channels, heads=num_heads, dropout=dropout))\n",
    "            self.batch_norms.append(torch.nn.BatchNorm1d(hidden_channels * num_heads))\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc = Linear(hidden_channels * num_heads, out_channels)\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "    \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # Apply TransformerConv layers\n",
    "        for conv, batch_norm in zip(self.convs, self.batch_norms):\n",
    "            x = conv(x, edge_index)\n",
    "            x = batch_norm(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "        \n",
    "        # Global pooling\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2ab32cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Train Loss: 0.2664, Val Loss: 0.2525, Val ROC-AUC: 0.7433\n",
      "Epoch: 02, Train Loss: 0.2347, Val Loss: 0.2891, Val ROC-AUC: 0.7458\n",
      "Epoch: 03, Train Loss: 0.2309, Val Loss: 0.3258, Val ROC-AUC: 0.7455\n",
      "Epoch: 04, Train Loss: 0.2299, Val Loss: 0.3679, Val ROC-AUC: 0.7424\n",
      "Epoch: 05, Train Loss: 0.2271, Val Loss: 0.3301, Val ROC-AUC: 0.7517\n",
      "Epoch: 06, Train Loss: 0.2267, Val Loss: 0.3233, Val ROC-AUC: 0.7574\n",
      "Epoch: 07, Train Loss: 0.2269, Val Loss: 0.3409, Val ROC-AUC: 0.7566\n",
      "Epoch: 08, Train Loss: 0.2238, Val Loss: 0.3166, Val ROC-AUC: 0.7624\n",
      "Epoch: 09, Train Loss: 0.2233, Val Loss: 0.3614, Val ROC-AUC: 0.7519\n",
      "Epoch: 10, Train Loss: 0.2224, Val Loss: 0.3552, Val ROC-AUC: 0.7581\n",
      "Epoch: 11, Train Loss: 0.2214, Val Loss: 0.3025, Val ROC-AUC: 0.7696\n",
      "Epoch: 12, Train Loss: 0.2217, Val Loss: 0.3228, Val ROC-AUC: 0.7660\n",
      "Epoch: 13, Train Loss: 0.2216, Val Loss: 0.3415, Val ROC-AUC: 0.7626\n",
      "Epoch: 14, Train Loss: 0.2208, Val Loss: 0.3154, Val ROC-AUC: 0.7607\n",
      "Epoch: 15, Train Loss: 0.2197, Val Loss: 0.3062, Val ROC-AUC: 0.7713\n",
      "Epoch: 16, Train Loss: 0.2177, Val Loss: 0.2955, Val ROC-AUC: 0.7655\n",
      "Epoch: 17, Train Loss: 0.2187, Val Loss: 0.3004, Val ROC-AUC: 0.7761\n",
      "Epoch: 18, Train Loss: 0.2186, Val Loss: 0.3170, Val ROC-AUC: 0.7612\n",
      "Epoch: 19, Train Loss: 0.2168, Val Loss: 0.2971, Val ROC-AUC: 0.7700\n",
      "Epoch: 20, Train Loss: 0.2174, Val Loss: 0.3265, Val ROC-AUC: 0.7632\n",
      "Epoch: 21, Train Loss: 0.2180, Val Loss: 0.3204, Val ROC-AUC: 0.7690\n",
      "Epoch: 22, Train Loss: 0.2154, Val Loss: 0.3445, Val ROC-AUC: 0.7668\n",
      "Epoch: 23, Train Loss: 0.2161, Val Loss: 0.3163, Val ROC-AUC: 0.7704\n",
      "Epoch: 24, Train Loss: 0.2146, Val Loss: 0.3480, Val ROC-AUC: 0.7722\n",
      "Epoch: 25, Train Loss: 0.2150, Val Loss: 0.3029, Val ROC-AUC: 0.7773\n",
      "Epoch: 26, Train Loss: 0.2146, Val Loss: 0.3323, Val ROC-AUC: 0.7725\n",
      "Epoch: 27, Train Loss: 0.2145, Val Loss: 0.3430, Val ROC-AUC: 0.7724\n",
      "Epoch: 28, Train Loss: 0.2132, Val Loss: 0.2869, Val ROC-AUC: 0.7761\n",
      "Epoch: 29, Train Loss: 0.2156, Val Loss: 0.3227, Val ROC-AUC: 0.7660\n",
      "Epoch: 30, Train Loss: 0.2133, Val Loss: 0.3325, Val ROC-AUC: 0.7691\n",
      "Test Loss: 0.3338, Test ROC-AUC: 0.7979\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model, optimizer, and loss function\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GraphTransformer(\n",
    "    in_channels=dataset.num_node_features,\n",
    "    hidden_channels=64,\n",
    "    out_channels=dataset.num_classes,\n",
    "    num_heads=4,\n",
    "    num_layers=3,\n",
    "    dropout=0.5\n",
    ").to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Training function\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        data.x = data.x.float()\n",
    "        data.y = data.y.float()\n",
    "        \n",
    "        # Mask valid labels (non-NaN)\n",
    "        mask = ~torch.isnan(data.y)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(out[mask], data.y[mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            data.x = data.x.float()\n",
    "            data.y = data.y.float()\n",
    "            \n",
    "            # Mask valid labels (non-NaN)\n",
    "            mask = ~torch.isnan(data.y)\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "            loss = criterion(out[mask], data.y[mask])\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            y_true.append(data.y[mask].cpu())\n",
    "            y_pred.append(out[mask].cpu())\n",
    "    \n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    \n",
    "    # Compute ROC-AUC\n",
    "    roc_auc = roc_auc_score(y_true.numpy(), y_pred.sigmoid().numpy(), average=\"macro\")\n",
    "    return total_loss / len(loader), roc_auc\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, 31):\n",
    "    train_loss = train()\n",
    "    val_loss, val_roc_auc = evaluate(val_loader)\n",
    "    print(f\"Epoch: {epoch:02d}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val ROC-AUC: {val_roc_auc:.4f}\")\n",
    "\n",
    "# Test the model\n",
    "test_loss, test_roc_auc = evaluate(test_loader)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test ROC-AUC: {test_roc_auc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
